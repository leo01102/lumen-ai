# PsyAI: Un Asistente con IA Emocional Multimodal

[![Estado del Proyecto](https://img.shields.io/badge/estado-en%20desarrollo-green.svg)](https://github.com/leo01102/psyai)
[![Licencia](https://img.shields.io/badge/licencia-MIT-blue.svg)](LICENSE)
[![Python Version](https://img.shields.io/badge/python-3.9%2B-blue.svg)](https://www.python.org/downloads/)

**PsyAI es un prototipo de asistente de IA que ofrece un apoyo emp√°tico mediante la detecci√≥n de emociones faciales y vocales, combinado con una interacci√≥n por voz en tiempo real.**

A diferencia de los chatbots tradicionales, PsyAI integra un an√°lisis emocional multimodal (rostro y voz) para comprender el estado completo del usuario y adaptar sus respuestas, buscando crear una experiencia de usuario m√°s humana y conectada.

<br>

<!-- ![GIF de la aplicaci√≥n en funcionamiento](docs/images/demo.gif) -->

_(Reemplazar con una captura de pantalla o GIF de la demo)_

---

## ‚ú® Caracter√≠sticas Principales

- **An√°lisis Emocional Multimodal:**
  - **Detecci√≥n de Emociones Faciales:** Utiliza la webcam para identificar en tiempo real emociones (ej. alegr√≠a, tristeza, enojo) usando `fer`.
  - **Reconocimiento de Emociones Vocales:** Analiza el tono de voz para detectar la emoci√≥n subyacente (ej. calma, felicidad, rabia) usando un modelo **Wav2Vec 2.0** optimizado.
- **Interacci√≥n por Voz Completa:** Conversa de forma natural con la IA gracias a un ciclo de audio completo:
  - **Transcripci√≥n en Tiempo Real:** Utiliza **Deepgram** para una transcripci√≥n r√°pida y precisa de la voz del usuario.
  - **Respuestas Habladas:** Genera audio con una voz natural usando **Edge-TTS**.
- **IA Conversacional de Alta Velocidad:** Se integra con el modelo **Llama 3.1** a trav√©s de la API de **Groq** para obtener respuestas casi instant√°neas.
- **Respuestas Emp√°ticas Contextualizadas:** El sistema combina el texto del usuario con el contexto emocional multimodal (facial + vocal) para generar respuestas m√°s consideradas y relevantes.
- **Memoria Persistente y Cifrada:** Recuerda hechos clave de conversaciones pasadas (ej. nombre, temas recurrentes) guard√°ndolos de forma segura en una base de datos **SQLite** local con cifrado AES.

---

## üõ†Ô∏è Stack Tecnol√≥gico

| √Årea                | Herramienta                                                    |
| :------------------ | :------------------------------------------------------------- |
| **IA & Backend**    | Python, **Groq (Llama 3.1)**, **Deepgram (STT)**, **Edge-TTS** |
| **An√°lisis Facial** | `fer` (TensorFlow)                                             |
| **An√°lisis Vocal**  | `transformers`, `Wav2Vec 2.0`, `ONNX Runtime`, `librosa`       |
| **Frontend**        | Streamlit, `streamlit-webrtc`, `audiorecorder`                 |
| **Base de Datos**   | SQLite, `cryptography` (para cifrado)                          |
| **Infraestructura** | Ejecuci√≥n Local (con APIs externas)                            |

Para una descripci√≥n detallada de la arquitectura, consulta el [**Documento de Informaci√≥n del Proyecto**](docs/01_project_info.md).

---

## üöÄ C√≥mo Empezar

Sigue estos pasos para poner en marcha el proyecto en tu m√°quina local.

### Prerrequisitos

- **Python 3.9‚Äì3.12.** Probado con **Python 3.11.9**.
- **Git** para clonar el repositorio.
- **Cuentas de API:**
  - Una cuenta en [**Groq**](https://console.groq.com/keys) para obtener una API Key.
  - Una cuenta en [**Deepgram**](https://console.deepgram.com/signup) para obtener una API Key.
- **(Opcional) Datos de Calibraci√≥n:** Si deseas optimizar el modelo de voz (requiere mucha RAM), descarga algunos archivos `.wav` de habla (ej. de [RAVDESS](https://zenodo.org/record/1188976)).

### 1. Instalaci√≥n del Proyecto

```bash
# 1. Clona el repositorio
git clone https://github.com/leo01102/psyai.git
cd psyai

# 2. Crea y activa un entorno virtual (recomendado)
python -m venv .venv
# En Windows:
.venv\Scripts\activate
# En macOS/Linux:
# source .venv/bin/activate

# 3. Instala todas las dependencias
pip install -r requirements.txt
```

### 2. Configuraci√≥n de API Keys y Cifrado

1.  En la ra√≠z del proyecto, crea un archivo llamado `.env`.
2.  Ejecuta el script para generar tu clave de cifrado local:
    ```bash
    python scripts/generate_key.py
    ```
3.  Copia la clave generada (`ENCRYPTION_KEY=...`) y p√©gala en tu archivo `.env`.
4.  A√±ade tus claves de API al mismo archivo `.env`:

    ```env
    # .env
    DEEPGRAM_API_KEY="TU_API_KEY_DE_DEEPGRAM"
    GROQ_API_KEY="TU_API_KEY_DE_GROQ"
    ENCRYPTION_KEY="TU_CLAVE_GENERADA_EN_EL_PASO_ANTERIOR"
    ```

### 3. Generaci√≥n de Modelos de IA Locales

Este proyecto utiliza una versi√≥n optimizada (ONNX) del modelo de emoci√≥n vocal. Debes generarla una sola vez ejecutando el siguiente script:

```bash
# Este script descargar√° el modelo de Hugging Face y lo convertir√°
python scripts/export_to_onnx.py
```

- El script crear√° autom√°ticamente los modelos `float32` y `dynamic_quant` en `ai_resources/models/voice_emotion/`.
- Te **preguntar√°** si deseas ejecutar la "cuantizaci√≥n est√°tica". Este paso es **opcional** y consume mucha RAM. Puedes escribir `n` (No) y la aplicaci√≥n funcionar√° perfectamente.

### 4. Ejecuci√≥n

Con el archivo `.env` configurado y los modelos generados, lanza la aplicaci√≥n:

```bash
streamlit run main.py
```

Abre tu navegador y ve a **http://localhost:8501**.

---

## üìÇ Estructura del Proyecto

El proyecto sigue una estructura modular para facilitar el mantenimiento. El c√≥digo fuente reside en `src/` y los modelos de IA en `ai_resources/`.

‚û°Ô∏è Para una explicaci√≥n detallada de cada carpeta y archivo, consulta la [**Gu√≠a de Estructura del Repositorio**](docs/02_structure_info.md).

---

## üó∫Ô∏è Roadmap y Futuras Mejoras

- [x] **Transcripci√≥n de Voz a Texto:** Implementado con Deepgram.
- [x] **An√°lisis de Emoci√≥n Facial:** Integrado con `fer`.
- [x] **An√°lisis de Emoci√≥n Vocal:** ¬°Implementado con Wav2Vec 2.0 y ONNX!
- [x] **Respuestas Multimodales:** El prompt de la IA ahora usa contexto facial y vocal.
- [x] **Persistencia y Memoria Cifrada:** Implementado con SQLite y `cryptography`.
- [x] **Ciclo de Audio Completo (TTS/STT):** Implementado.
- [x] **Mejorar Componentes UI:** L√≥gica de renderizado movida a `src/ui/components.py`.

---

## ü§ù Contribuciones

Este es un proyecto en crecimiento y las ideas son bienvenidas. Si deseas contribuir, por favor sigue el flujo de trabajo est√°ndar de Fork y Pull Request.

---

## üìÑ Licencia

Este proyecto est√° bajo la Licencia MIT. Consulta el archivo [LICENSE](LICENSE) para m√°s detalles.
